# Jupyter Claude

> Proyecto de Jupyter Notebooks configurado con uv y Python 3.12, diseÃ±ado para proyectos de Machine Learning end-to-end con mejores prÃ¡cticas integradas.

**Este README es para ti, el desarrollador**. Si estÃ¡s trabajando con Claude Code en este proyecto, ten en cuenta que Claude tiene su propia guÃ­a tÃ©cnica en `CLAUDE.md` que usa como referencia interna.

## Â¿Por quÃ© este proyecto?

Este repositorio es mÃ¡s que un simple setup de Jupyter Notebooks. Es un marco de trabajo completo para desarrollar proyectos de **Machine Learning de principio a fin**, desde la exploraciÃ³n inicial de datos hasta el deployment de modelos en producciÃ³n.

## CaracterÃ­sticas

- **Python 3.12** - La Ãºltima versiÃ³n estable
- **uv** - GestiÃ³n de dependencias ultrarrÃ¡pida
- **Jupyter Notebook/Lab** - Entorno completamente configurado
- **Estructura de proyecto ML** - OrganizaciÃ³n profesional para proyectos end-to-end
- **GuÃ­a completa de mejores prÃ¡cticas** - En `CLAUDE.md` para Claude y este README para ti
- **Ejemplos prÃ¡cticos** - CÃ³digo listo para usar y adaptar

## Requisitos

- [uv](https://github.com/astral-sh/uv) instalado en tu sistema

## InstalaciÃ³n

1. Clona el repositorio:
```bash
git clone https://github.com/TU_USUARIO/jupyter_claude.git
cd jupyter_claude
```

2. Las dependencias se instalarÃ¡n automÃ¡ticamente cuando ejecutes cualquier comando con `uv run`:
```bash
uv sync
```

## Uso

### Iniciar Jupyter Notebook

```bash
uv run jupyter notebook
```

### Iniciar JupyterLab

```bash
uv run jupyter lab
```

### Ejecutar el notebook de ejemplo

```bash
# Como script Python
uv run python test_notebook.py

# O abre ejemplo.ipynb en Jupyter
uv run jupyter notebook ejemplo.ipynb
```

## Estructura del Proyecto

```
jupyter_claude/
â”œâ”€â”€ CLAUDE.md              # GuÃ­a de mejores prÃ¡cticas para Jupyter Notebooks
â”œâ”€â”€ README.md              # Este archivo
â”œâ”€â”€ ejemplo.ipynb          # Notebook de ejemplo
â”œâ”€â”€ test_notebook.py       # Script de prueba del notebook
â”œâ”€â”€ pyproject.toml         # ConfiguraciÃ³n del proyecto y dependencias
â”œâ”€â”€ uv.lock                # Lock file de dependencias
â””â”€â”€ .gitignore             # Archivos ignorados por git
```

---

## ðŸš€ Proyectos de Machine Learning End-to-End

Este proyecto estÃ¡ optimizado para desarrollar proyectos completos de ML siguiendo las mejores prÃ¡cticas de la industria.

### El Pipeline de ML

Un proyecto de Machine Learning profesional sigue este flujo:

```
1. DefiniciÃ³n del Problema
   â†“
2. RecopilaciÃ³n de Datos
   â†“
3. AnÃ¡lisis Exploratorio (EDA)
   â†“
4. PreparaciÃ³n de Datos
   â†“
5. Feature Engineering
   â†“
6. Modelado
   â†“
7. EvaluaciÃ³n
   â†“
8. Deployment
   â†“
9. Monitoreo
```

### Estructura Recomendada para Proyectos ML

Cuando empieces un nuevo proyecto de ML, organiza tu directorio asÃ­:

```
mi_proyecto_ml/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Datos originales (Â¡nunca modificar!)
â”‚   â”œâ”€â”€ interim/          # Datos en proceso de transformaciÃ³n
â”‚   â”œâ”€â”€ processed/        # Datos finales listos para modelar
â”‚   â””â”€â”€ external/         # Datos de fuentes externas
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb                    # AnÃ¡lisis Exploratorio
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb          # Limpieza y PreparaciÃ³n
â”‚   â”œâ”€â”€ 03_feature_engineering.ipynb    # CreaciÃ³n de Features
â”‚   â”œâ”€â”€ 04_modeling.ipynb               # Entrenamiento de Modelos
â”‚   â””â”€â”€ 05_evaluation.ipynb             # EvaluaciÃ³n y ComparaciÃ³n
â”‚
â”œâ”€â”€ src/                  # CÃ³digo de producciÃ³n (no notebooks)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ load_data.py
â”‚   â”‚   â””â”€â”€ preprocess.py
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ build_features.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â””â”€â”€ predict.py
â”‚   â””â”€â”€ visualization/
â”‚       â””â”€â”€ visualize.py
â”‚
â”œâ”€â”€ models/               # Modelos entrenados (.pkl, .h5, etc.)
â”œâ”€â”€ reports/              # AnÃ¡lisis generados
â”‚   â””â”€â”€ figures/          # GrÃ¡ficos y visualizaciones
â”œâ”€â”€ config/               # Archivos de configuraciÃ³n
â”œâ”€â”€ tests/                # Tests unitarios
â”œâ”€â”€ pyproject.toml        # Dependencias (gestionadas por uv)
â””â”€â”€ README.md             # DocumentaciÃ³n del proyecto
```

### Fases del Proyecto ML

#### Fase 1: DefiniciÃ³n del Problema

**Lo primero es lo primero**: Â¿QuÃ© problema estÃ¡s resolviendo?

- Â¿Es un problema de clasificaciÃ³n o regresiÃ³n?
- Â¿QuÃ© mÃ©tricas usarÃ¡s para medir el Ã©xito?
- Â¿CuÃ¡l es el baseline (rendimiento sin ML)?
- Â¿QuÃ© constraints tienes? (latencia, recursos, interpretabilidad)

**Tip**: Documenta esto en un notebook `00_problem_definition.ipynb` antes de empezar.

#### Fase 2: AnÃ¡lisis Exploratorio de Datos (EDA)

Esta es la fase mÃ¡s importante. AquÃ­ descubres:

- Forma y tamaÃ±o de tus datos
- Tipos de variables
- Valores faltantes y su patrÃ³n
- DistribuciÃ³n de las variables
- Outliers y anomalÃ­as
- Correlaciones entre variables
- Desbalanceo de clases (en clasificaciÃ³n)

**Checklist rÃ¡pido de EDA**:
- [ ] Verificar dimensiones del dataset
- [ ] Revisar tipos de datos
- [ ] Analizar valores faltantes
- [ ] Detectar duplicados
- [ ] Visualizar distribuciones
- [ ] Calcular correlaciones
- [ ] Identificar outliers

#### Fase 3: PreparaciÃ³n de Datos

Los datos nunca vienen perfectos. NecesitarÃ¡s:

**Manejo de valores faltantes**:
- ImputaciÃ³n por media/mediana (variables numÃ©ricas)
- ImputaciÃ³n por moda (variables categÃ³ricas)
- KNN Imputation (mÃ¡s sofisticado)
- EliminaciÃ³n (si es < 5% de los datos)

**Tratamiento de outliers**:
- DetecciÃ³n por IQR o Z-score
- Capping (limitar a percentiles)
- TransformaciÃ³n logarÃ­tmica
- EliminaciÃ³n justificada

**Encoding de variables categÃ³ricas**:
- One-Hot Encoding (para variables nominales)
- Label Encoding (para variables ordinales)
- Target Encoding (cuando hay muchas categorÃ­as)
- Frequency Encoding

**Escalado de features**:
- StandardScaler: para distribuciones normales
- MinMaxScaler: para rangos especÃ­ficos [0,1]
- RobustScaler: cuando hay outliers

#### Fase 4: Feature Engineering

AquÃ­ es donde diferencias un proyecto bÃ¡sico de uno profesional:

**CreaciÃ³n de features**:
- Features polinomiales (xÂ², xÂ³)
- Interacciones entre variables (xâ‚ Ã— xâ‚‚)
- Features de datetime (aÃ±o, mes, dÃ­a de semana)
- Agregaciones por grupos (media por categorÃ­a)
- Domain-specific features (basadas en conocimiento del negocio)

**SelecciÃ³n de features**:
- CorrelaciÃ³n con el target
- Importancia por Random Forest
- Recursive Feature Elimination (RFE)
- SelectKBest con diferentes scores

**Por quÃ© importa**: MÃ¡s features â‰  mejor modelo. Features irrelevantes aÃ±aden ruido y overfitting.

#### Fase 5: Modelado

**Empieza simple, luego complejiza**:

1. **Baseline Model**: Siempre empieza con un modelo simple (DummyClassifier, media, etc.)
2. **Modelos Lineales**: Logistic/Linear Regression
3. **Ãrboles**: Decision Trees, Random Forest
4. **Boosting**: XGBoost, LightGBM, CatBoost
5. **Deep Learning**: Solo si tienes suficientes datos y recursos

**DivisiÃ³n de datos**:
```python
# Train-Validation-Test split
Train (70%): Entrenar el modelo
Validation (15%): Tuning de hiperparÃ¡metros
Test (15%): EvaluaciÃ³n final (tocar solo una vez)
```

**Hyperparameter Tuning**:
- Grid Search: exhaustivo pero lento
- Random Search: mÃ¡s rÃ¡pido, buena exploraciÃ³n
- Optuna/Bayesian Optimization: lo mÃ¡s eficiente

**Cross-Validation**:
- K-Fold: para datasets balanceados
- Stratified K-Fold: para clasificaciÃ³n desbalanceada
- Time Series Split: para datos temporales

#### Fase 6: EvaluaciÃ³n

**Para ClasificaciÃ³n**:
- Accuracy: solo si las clases estÃ¡n balanceadas
- Precision/Recall: cuando el costo de FP y FN difiere
- F1-Score: balance entre precision y recall
- ROC-AUC: rendimiento general del clasificador
- Confusion Matrix: entender quÃ© se estÃ¡ confundiendo

**Para RegresiÃ³n**:
- MAE (Mean Absolute Error): interpretable, en mismas unidades
- RMSE (Root Mean Squared Error): penaliza errores grandes
- RÂ²: quÃ© % de varianza explica el modelo
- MAPE: error porcentual (cuidado con divisiones por 0)

**Interpretabilidad**:
- SHAP values: impacto de cada feature
- LIME: explicaciones locales
- Feature importance: quÃ© features son mÃ¡s importantes

#### Fase 7: Deployment

Tu modelo necesita servir predicciones en el mundo real:

**SerializaciÃ³n**:
```python
import joblib
joblib.dump(model, 'model.pkl')  # Guardar
model = joblib.load('model.pkl')  # Cargar
```

**API de PredicciÃ³n** (con FastAPI):
```python
from fastapi import FastAPI
import joblib

app = FastAPI()
model = joblib.load('model.pkl')

@app.post("/predict")
def predict(features: list):
    prediction = model.predict([features])
    return {"prediction": prediction[0]}
```

**DockerizaciÃ³n**:
```dockerfile
FROM python:3.12
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["uvicorn", "app:app", "--host", "0.0.0.0"]
```

#### Fase 8: Monitoreo

El trabajo no termina en deployment:

- **Data Drift**: Â¿Han cambiado las distribuciones de entrada?
- **Concept Drift**: Â¿Ha cambiado la relaciÃ³n Xâ†’y?
- **Performance Monitoring**: Â¿El modelo sigue siendo preciso?
- **Reentrenamiento**: Estrategia para actualizar el modelo

### Herramientas Esenciales por Fase

| Fase | LibrerÃ­as Clave |
|------|----------------|
| EDA | pandas, numpy, matplotlib, seaborn, plotly |
| Preprocessing | scikit-learn, pandas |
| Feature Engineering | feature-engine, category_encoders |
| Modelado | scikit-learn, xgboost, lightgbm, catboost |
| Deep Learning | tensorflow, pytorch, keras |
| Interpretabilidad | shap, lime, eli5 |
| Tracking | mlflow, wandb |
| Deployment | fastapi, docker, kubernetes |
| Monitoreo | evidently, whylabs |

### Checklist de Proyecto Completo

**Antes de considerar tu proyecto "terminado"**, asegÃºrate de haber:

- [ ] Definido claramente el problema y las mÃ©tricas
- [ ] Realizado EDA exhaustivo
- [ ] Manejado valores faltantes y outliers
- [ ] Creado y seleccionado features relevantes
- [ ] Probado mÃºltiples modelos
- [ ] Realizado cross-validation
- [ ] Evaluado con conjunto de test independiente
- [ ] Comparado contra baseline
- [ ] Analizado interpretabilidad
- [ ] Serializado el modelo y pipeline completo
- [ ] Documentado todo el proceso
- [ ] Creado API de predicciÃ³n (si aplica)
- [ ] Configurado monitoreo (para producciÃ³n)

---

## Mejores PrÃ¡cticas para Jupyter Notebooks

Consulta el archivo `CLAUDE.md` para una guÃ­a completa tÃ©cnica. AquÃ­ un resumen ejecutivo:

### OrganizaciÃ³n
- Importaciones siempre al inicio
- Flujo de arriba hacia abajo
- Una idea por celda
- Usa Markdown para documentar

### Reproducibilidad
- Establece seeds aleatorias (`np.random.seed(42)`)
- El notebook debe poder ejecutarse de arriba hacia abajo sin errores
- Reinicia el kernel regularmente para verificar

### CÃ³digo Limpio
- Nombres de variables descriptivos
- Funciones para lÃ³gica repetitiva
- Celdas de mÃ¡ximo 50 lÃ­neas
- Extrae cÃ³digo complejo a mÃ³dulos .py

### VisualizaciÃ³n
- Siempre tÃ­tulos, etiquetas y leyendas
- Usa `head()`, `tail()` para DataFrames grandes
- Configura tamaÃ±os de figura apropiados

### Control de Versiones
- AÃ±ade notebooks a git
- Considera limpiar outputs antes de commit
- Usa `.gitignore` apropiado (incluido en este proyecto)

## Dependencias Principales

- `jupyter` - Jupyter Notebook
- `notebook` - Interfaz web de Jupyter
- `ipykernel` - Kernel de IPython
- `numpy` - ComputaciÃ³n numÃ©rica

Para ver todas las dependencias, consulta `pyproject.toml`.

## Contribuir

Las contribuciones son bienvenidas. Por favor:

1. Haz fork del proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la licencia MIT.

## Autor

Creado con Claude Code
